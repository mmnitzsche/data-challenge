# üöÄ Data Challenge - Looqbox

Este reposit√≥rio cont√©m a minha solu√ß√£o para o desafio de dados proposto pela [Looqbox](https://github.com/looqbox/data-challenge). O desafio √© dividido em tr√™s partes (cases) + um teste de SQL, cada uma com um foco diferente de an√°lise e manipula√ß√£o de dados.

---

## üìÅ Estrutura do Reposit√≥rio

<span style="font-size: 30px;">üö®</span>
<span style="font-size: 16px; font-weight: bold;">Importante:</span>
<span style="font-size: 16px;">
Para conectar ao banco de dados de forma segura, √© necess√°rio configurar a vari√°vel de ambiente <code>DATABASE_URL</code>.
Em ambiente local, essa configura√ß√£o deve ser feita em um arquivo <code>.env</code>.<br>
<br>
Streamlit:  [Dashboard em publicado](https://imdb-dashboard.streamlit.app/)
<br>
Caso queira publicar essa solu√ß√£o no Stramlit (Streamlit Cloud), a vari√°vel da string de conex√£o deve ser adicionada na se√ß√£o <code>Settings > Secrets</code> do seu aplicativo.
</span>
---

`.env`
 ``` py
  DATABASE_URL=protocolo+driver://usuario:senha@endereco_do_host/nome_do_banco
```

```
‚îú‚îÄ‚îÄ .devcontainer
‚îÇ   ‚îî‚îÄ‚îÄ devcontainer.json
‚îú‚îÄ‚îÄ case1
‚îÇ   ‚îú‚îÄ‚îÄ case_1.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ sql_queries.py
‚îú‚îÄ‚îÄ case2
‚îÇ   ‚îú‚îÄ‚îÄ case_2.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ sql_queries.py
‚îú‚îÄ‚îÄ case3
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ functions.py
‚îÇ   ‚îî‚îÄ‚îÄ sql_queries.py
‚îú‚îÄ‚îÄ media
‚îÇ   ‚îú‚îÄ‚îÄ cards_title.png
‚îÇ   ‚îú‚îÄ‚îÄ filters.gif
‚îÇ   ‚îú‚îÄ‚îÄ hint_multbox.gif
‚îÇ   ‚îú‚îÄ‚îÄ table_filter.gif
‚îÇ   ‚îî‚îÄ‚îÄ top_metrics.gif
‚îú‚îÄ‚îÄ sql_test
‚îÇ   ‚îú‚îÄ‚îÄ case-1-1.sql
‚îÇ   ‚îú‚îÄ‚îÄ case-1-2.sql
‚îÇ   ‚îî‚îÄ‚îÄ case-1-3.sql
‚îú‚îÄ‚îÄ venv
‚îÇ   ‚îî‚îÄ‚îÄ pyvenv.cfg
‚îú‚îÄ‚îÄ __pycache__
‚îÇ   ‚îú‚îÄ‚îÄ connection.cpython-311.pyc
‚îÇ   ‚îî‚îÄ‚îÄ connection_string.cpython-311.pyc
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ connection.py
‚îú‚îÄ‚îÄ connection_string.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üì¶ Requisitos

- Python 3.10+
- Bibliotecas listadas em `requirements.txt`

Para instalar os requisitos, utilize:

```bash
pip install -r requirements.txt
```

___
## üß† Resolu√ß√£o dos desafios  
Nesse documento vai conter apenas um resumo das quest√µes do desafio Caso queira ver os as quest√µes do desafios com mais detalhes acesse o reposit√≥rio: [Looqbox](https://github.com/looqbox/data-challenge)


# 0Ô∏è‚É£ SQL TEST

### **SQL TEST.1** - **Quest√£o**: What are the 10 most expensive products in the company?

```sql
SELECT
    product_cod,
    product_name,
    product_val
FROM `looqbox-challenge`.data_product
ORDER BY product_val DESC
LIMIT 10;
```

> üí° **Descri√ß√£o da Solu√ß√£o:** Foi apenas achar a tabela que era a respons√°vel por conter o valor "cheio" dos produtos, ordenar a coluna `PRODUCT_VAL` que respons√°vel pelo valor, ordernar por `DESC` e limitar o retorno em 10 linhas, como pedido na quest√£o usando o `LIMIT 10`

| C√≥digo  | Produto                                                                 | Pre√ßo  |
|---------|-------------------------------------------------------------------------|------------|
| 320046  | Escova Dental Eletrica ORAL B D34 Professional Care 5000 110v           | 399.90     |
| 315481  | Cafeteira Expresso 3 CORACOES Tres Modo Vermelho                        | 499.00     |
| 311397  | Conjunto de Panelas Allegra em Inox TRAMONTINA 5 Pecas Gratis Utensilios 5 Pecas | 359.00     |
| 301409  | Whisky Escoces THE MACALLAN Ruby Garrafa 700ml com Caixa                | 741.99     |
| 190817  | Champagne Rose VEUVE CLICQUOT PONSARDIM Garrafa 750ml                   | 366.90     |
| 176185  | Whisky Escoces JOHNNIE WALKER Blue Label Garrafa 750ml                  | 735.90     |
| 154431  | Champagne Frances Brut Imperial MOET & CHANDON Garrafa 750ml            | 315.90     |
| 153795  | Champagne Frances Brut Imperial MOET Rose Garrafa 750ml                 | 359.90     |
| 147706  | Whisky Escoces CHIVAS REGAL 18 Anos Garrafa 750ml                       | 329.90     |
| 100280  | Vinho Portugues Tinto Vintage QUINTA DO CRASTO Garrafa 750ml            | 445.90     |



<br>

### **SQL TEST.2** - **Quest√£o**: What sections do the ``BEBIDAS`` and ``PADARIA`` departments have?

```sql
SELECT DISTINCT
    SECTION_NAME
FROM `looqbox-challenge`.data_product
WHERE
    DEP_NAME IN ('BEBIDAS', 'PADARIA')
ORDER BY SECTION_NAME;
```

> üí° **Descri√ß√£o da Solu√ß√£o:** quando identifiquei que os valores estavam na tabela `.data_product` eu fiz um `WHERE` onde estava a coluna dos departamentos (`dep_name`) e ordenei pelo nome de se√ß√£o (`section_name`)

| Departamento          |
|----------------------|
| BEBIDAS              |
| CERVEJAS             |
| DOCES-E-SOBREMESAS   |
| GESTANTE             |
| PADARIA              |
| QUEIJOS-E-FRIOS      |
| REFRESCOS            |
| VINHOS               |


### **SQL TEST.3** - **Quest√£o**:What was the total sale of products (in $) of each Business Area in the first quarter of 2019?

```sql
SELECT
    c.BUSINESS_NAME        AS business_area,
    SUM(s.SALES_VALUE)     AS total_sales_usd
FROM `looqbox-challenge`.data_store_sales AS s
JOIN `looqbox-challenge`.data_store_cad   AS c
      ON s.STORE_CODE = c.STORE_CODE
WHERE s.DATE >= '2019-01-01'
  AND s.DATE <  '2019-04-01'    
GROUP BY c.BUSINESS_NAME
ORDER BY total_sales_usd DESC;
```
> üí° **Descri√ß√£o da Solu√ß√£o:**  
> Para obter o total de vendas  (`SALES_VALUE`) por √°rea de neg√≥cio (`BUSINESS_NAME`) durante o **primeiro trimestre de 2019** (de 1¬∫ de janeiro a 31 de mar√ßo). Usei menor que  `< 2019-04-01`
> 
> Fiz um `JOIN` entre as tabelas `data_store_sales` e `data_store_cad` com base na coluna `STORE_CODE`, garantindo que os dados de venda sejam associados.
> 
> Em seguida, filtrei os dados de vendas para incluir apenas o per√≠odo desejado.  
> 
> agrupei por √°rea de neg√≥cio (`BUSINESS_NAME`) e a soma das vendas (`SALES_VALUE`) foi calculada para cada grupo.  
> 
> Por fim, os resultados s√£o ordenados em ordem decrescente de vendas totais (`total_sales_usd`).

| √Årea de Neg√≥cio | Total de Vendas (US$) |
|------------------|------------------------|
| Farma            | 81.776.691,73          |
| Varejo           | 81.032.347,65          |
| Atacado          | 80.384.884,60          |
| Proximidade      | 80.171.122,80          |
| Posto            | 32.072.326,40          |

___

# 1Ô∏è‚É£ Case 1


### **Quest√£o**:  The Dev Team was tired of developing the same old queries just varying the filters accordingly to their boss demands.
As a new member of the crew, your mission now is to create a dynamic function in Python, on the most flexible of ways, to produce queries and retrieve a dataframe based on three parameters:

- product_code: integer
- store_code: integer
- date: list of ISO-like strings
- Date e.g. ``['2019-01-01', '2019-01-31']``

```py
#%%
import pandas as pd
import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from connection import read_database  

def retrieve_data(product_code: int, store_code: int, date: list) -> pd.DataFrame:
    try:
        start_date, end_date = date
        query = f"""
        SELECT *
        FROM data_product_sales
        WHERE PRODUCT_CODE = {product_code}
          AND STORE_CODE = {store_code}
          AND DATE BETWEEN '{start_date}' AND '{end_date}'
        """

        df = read_database(query)
        return df

    except Exception as e:
        print(f"Erro ao recuperar dados: {e}")
        return pd.DataFrame()
```

> üí° **Descri√ß√£o da Solu√ß√£o:**  
> Para recuperar os dados criei a `retrieve_data`, que recebe como par√¢metros o c√≥digo do produto (`product_code`), o c√≥digo da loja (`store_code`) e uma lista com duas datas (`date`) representando o in√≠cio e o fim do per√≠odo desejado.  
> A partir desses par√¢metros, construo uma query SQL dinamicamente utilizando f-string (<em>usei ``'''`` para deixar mais leg√≠vel</em>) para filtrar os dados da tabela `data_product_sales` com base nas colunas `PRODUCT_CODE`, `STORE_CODE` e `DATE`. Em seguida, utilizo a fun√ß√£o `read_database` para executar essa query e carregar os dados em um DataFrame do Pandas.

<br>

## üõ†Ô∏è Como executar
```bash
cd .\case1\ 
python main.py
```
___
# 2Ô∏è‚É£ Case 2

### **Quest√£o**: A brand new client sent you two ready-to-go queries. Those are listed below:

**Query 1:**
``` sql
SELECT
      STORE_CODE,
      STORE_NAME,
      START_DATE,
      END_DATE,
      BUSINESS_NAME,
      BUSINESS_CODE
FROM data_store_cad
```

**Query 2:**
``` sql
SELECT
        STORE_CODE,
        DATE,
        SALES_VALUE,
        SALES_QTY
FROM data_store_sales
WHERE DATE BETWEEN '2019-01-01' AND '2019-12-31'
In addition, he gave you this set of instructions:
```
Use the queries as they are (do not modify them or create a new one);

Please filter the period between this given range: `['2019-10-01','2019-12-31']`

> üí° **Descri√ß√£o da Solu√ß√£o:**  
> Para calcular o **Ticket M√©dio (TM)** por loja e categoria, comecei importando os dados das tabelas `data_store_sales` e `data_store_cad` usando a fun√ß√£o `read_database` com as queries pr√© estabelecidas (<em>das quais as queries j√° est√£o prontas no arquivo `case2/sql_queries.py`</em>).
> Em seguida, realizei um `merge` entre essas duas bases utilizando a coluna `STORE_CODE` como chave, garantindo que cada venda fosse associada √† loja e √† categoria correta.  
<br>
> Ap√≥s isso, agrupei os dados por `STORE_NAME` e `BUSINESS_NAME`, somando os valores de `SALES_VALUE` (valor vendido) e `SALES_QTY` (quantidade vendida).  
> Com esses dados agregados, calculei o **Ticket M√©dio (TM)** dividindo o valor vendido pela quantidade de itens vendidos, e arredondei o resultado para duas casas decimais. Pra ficar igual ao dataframe sugerido.
```python
resumo["TM"] = (resumo["SALES_VALUE"] / resumo["SALES_QTY"]).round(2)
```
> Por fim, renomeei as colunas para `Loja`, `Categoria` e `TM`, retornando apenas essas tr√™s informa√ß√µes no dataframe final.
<br>

| Loja            | Categoria     | TM    |
|------------------|---------------|--------|
| Bahia           | Atacado       | 15.39 |
| Bangkok         | Posto         | 13.67 |
| Belem           | Proximidade   | 15.37 |
| Berlin          | Proximidade   | 15.39 |
| Buenos Aires    | Atacado       | 15.39 |
| Chicago         | Varejo        | 15.53 |
| Dubai           | Atacado       | 15.39 |
| Hong Kong       | Farma         | 26.33 |
| London          | Farma         | 28.96 |
| Madri           | Farma         | 29.00 |
| Miami           | Posto         | 13.67 |
| New York        | Proximidade   | 15.39 |
| Paris           | Proximidade   | 15.39 |
| Rio de Janeiro  | Farma         | 29.56 |
| Roma            | Varejo        | 15.39 |
| Salvador        | Atacado       | 15.39 |
| Sao Paulo       | Varejo        | 15.39 |
| Sidney          | Posto         | 13.67 |
| Tokio           | Varejo        | 15.39 |



## üõ†Ô∏è Como executar

```bash
cd .\case2\ 
python main.py
```
____
<br>

# 3Ô∏è‚É£ Case 3

### **Case 3** - **Quest√£o**: Building your own visualization
Create at least one chart using the table IMDB_movies. The code must be in Python, and you are free to use any libraries, data in the table and graphic format. Explain why you chose the visualization (or visualizations) you are submitting.


### üîπ `Visuais e Dashboard`
> üí° **Descri√ß√£o da Solu√ß√£o:**  
> Para construir um dashboard com os dados do IMDB, utilizei o **Streamlit** em conjunto com **Plotly** e **Pandas**. Separei o projeto em tr√™s arquivos principais:  
<br>
> `app.py`, respons√°vel por toda a parte visual e l√≥gica do dashboard; <br>
`functions.py`, onde concentro todas as fun√ß√µes auxiliares; <br>`sql_queries.py`, que guarda as queries SQL de forma organizada.  
>
> A conex√£o com o banco de dados foi feita usando uma fun√ß√£o chamada `read_database`, e na vers√£o de produ√ß√£o, estou utilizando as **credenciais via `secrets` do pr√≥prio Streamlit Cloud**.  
>> Toda essa estrutura foi pensada para ser **modular**, **escal√°vel** e **f√°cil de manter**, separando responsabilidades em arquivos distintos e aproveitando os recursos do Streamlit.
>
> **Destaques da solu√ß√£o:**
> - Criei filtros din√¢micos de **atores**, **g√™neros** e **ano** de lan√ßamento, interdependentes: ao selecionar um ator, os g√™neros se ajustam com base na nova filtragem (e vice-versa).
![alt text](media/filters.gif)
>
><br>
><br>

> - Exibi os principais indicadores em `metrics`/`cards` no topo do dashboard, como **total de filmes**, **rating m√©dio** e **receita total**.
![alt text](media/cards_title.png)
>
><br>
><br>


> - Criei explica√ß√µes personalizadas para as op√ß√µes dos `selectbox`, para tornar a navega√ß√£o mais intuitiva; o famoso 'hint'.
![alt text](media/hint_multbox.gif)
>
><br>
><br>

> - ü•á Implementei uma visualiza√ß√£o de **Top 10** com `Plotly Express`, baseada na m√©trica Y (ex: revenue, Rating) e agrupada pela m√©trica X (ex: Genre, Year). Voc√™ pode alterar a m√©trica de ambos os eixos se necess√°rio, isso evita a cria√ß√£o de multiplos visuais e deixa a aplica√ß√£o mais simples e perform√°tica.
![alt text](media/top_metrics.gif)
>
><br>
><br>

> - Por fim, exibo a tabela filtrada no final para permitir an√°lise direta do dataset e filtro tamb√©m aplicado.
![alt text](media/table_filter.gif)
>


<br>

### üîπ `C√≥digos e fun√ß√µes:`
> üí° **Leitura e Pr√©-processamento dos Dados:**  
> Os dados foram carregados diretamente do banco de dados com a fun√ß√£o `read_database`, a partir de uma query definida no m√≥dulo `sql_queries.py`.  
> Em seguida, registros com valores ausentes em colunas cr√≠ticas como `Rating`, `RevenueMillions`, `Actors`, `Genre` e `Year` foram descartados para garantir qualidade na an√°lise.  
>  
> Ap√≥s isso, foram aplicadas as fun√ß√µes `ensure_list_format` e `clean_list_items` para converter colunas de texto (`Actors` e `Genre`) em listas limpas, permitindo filtros m√∫ltiplos e buscas parciais.

> üí° **Gera√ß√£o de Filtros Din√¢micos:**  
> Atrav√©s de fun√ß√µes como `get_filtered_actors` e `get_filtered_genres`, foram criadas listas de op√ß√µes que se atualizam de acordo com as sele√ß√µes atuais do usu√°rio.  
> Isso permite, por exemplo, que ao selecionar um g√™nero, apenas os atores que atuaram nesse g√™nero fiquem dispon√≠veis no filtro de atores (e vice-versa).  
>  
> Para isso, os filtros aplicam a fun√ß√£o `filter_df_by_list_contains`, que verifica se qualquer item da lista do usu√°rio est√° contido nos itens da coluna (`Genre` ou `Actors`).

> üí° **Aplica√ß√£o dos Filtros no DataFrame:**  
> Ap√≥s o ajuste dos filtros, o dataframe √© filtrado por:
> - Intervalo de anos escolhido no slider
> - Atores e/ou g√™neros selecionados  
> Isso resulta no dataframe `df_filtered`, base principal usada no restante do dashboard.

--

> üí° **`ensure_list_format`:**  
> Converte valores que s√£o `str` em listas (usando split por v√≠rgula), ou retorna listas j√° existentes.  
> Garante consist√™ncia no formato dos dados para aplicar filtros de forma robusta.

> üí° **`clean_list_items`:**  
> Percorre listas e aplica `.strip()` em cada item, removendo espa√ßos em branco indesejados.

> üí° **`filter_df_by_list_contains`:**  
> Recebe um dicion√°rio de filtros (`{"Actors": [...], "Genre": [...]}`) e aplica uma filtragem em qualquer linha onde **pelo menos um dos termos** est√° presente (com `lower()` para garantir case-insensitive).  
> Essa fun√ß√£o √© o cora√ß√£o da l√≥gica de filtragem m√∫ltipla.

> üí°  `get_filtered_actors` e `get_filtered_genres`:
> Respons√°veis por retornar os valores dispon√≠veis para os filtros din√¢micos da interface, com base nas sele√ß√µes atuais.  
> Elas utilizam `filter_df_by_list_contains` para refinar as op√ß√µes de filtro oferecidas ao usu√°rio.
> üí°  `update_selected_genres` e `update_selected_actors`:
> Atualizam o estado de sele√ß√£o (`st.session_state`) com base nas escolhas do usu√°rio, permitindo reatividade e manuten√ß√£o da sele√ß√£o mesmo com re-renderiza√ß√£o da interface.


Estrutura:
```
‚îú‚îÄ‚îÄ case3/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ functions.py
‚îÇ   ‚îî‚îÄ‚îÄ sql_queries.py
```

## üõ†Ô∏è Como executar

```bash
cd .\case3\ 
streamlit run app.py
```

## üë®‚Äçüíª Author

Developed by Mateus Nitzsche. 
[Blog](https://blog-mmnitzsches-projects.vercel.app/)
 | [Linkedin](https://www.linkedin.com/in/mateusnit/)
 | [Github](https://github.com/mmnitzsche/)
